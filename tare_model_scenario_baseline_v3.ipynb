{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b97433",
   "metadata": {},
   "source": [
    "# Load Util File with TARE Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d74abe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: c:\\Users\\14128\\Research\\cmu-tare-model\n",
      "File path: c:\\Users\\14128\\Research\\cmu-tare-model\\tare_model_functions_v2.3.ipynb\n",
      "File not found: tare_model_functions_v2.3.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Measure Package 0: Baseline\n",
    "menu_mp = 0\n",
    "input_mp = 'baseline'\n",
    "\n",
    "# Get the current working directory of the project\n",
    "project_root = os.path.abspath(os.getcwd())\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "# Relative path to the file from the project root\n",
    "relative_path = r\"tare_model_functions_v3.ipynb\"\n",
    "\n",
    "# Construct the absolute path to the file\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "print(f\"File path: {file_path}\")\n",
    "\n",
    "# Run the notebook and import variables\n",
    "if os.path.exists(relative_path):\n",
    "    get_ipython().run_line_magic('run', f'-i \"{relative_path}\"')\n",
    "    print(\"Loaded All TARE Model Functions\")\n",
    "else:\n",
    "    print(f\"File not found: {relative_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67d1f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result outputs will be exported here: c:\\Users\\14128\\Research\\cmu-tare-model\\output_results\n"
     ]
    }
   ],
   "source": [
    "# Storing Result Outputs in output_results folder\n",
    "relative_path = r\"output_results\"\n",
    "output_folder_path = os.path.join(project_root, relative_path)\n",
    "print(f\"Result outputs will be exported here: {output_folder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91735848",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Baseline: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65dfbc9",
   "metadata": {
    "id": "lFPOJw1AV-ln"
   },
   "source": [
    "## Simulate Residential Energy Consumption\n",
    "- Filter EUSS Data: Only occupied units and Single Family Homes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417135d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ``inline`` flag will use the appropriate backend to make figures appear inline in the notebook.  \n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# `plt` is an alias for the `matplotlib.pyplot` module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn library (wrapper of matplotlib)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# For regex, import re\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current datetime\n",
    "# Start the timer\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48505a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Welcome to the Trade-off Analysis of residential Retrofits for energy Equity Tool (TARE Model)\n",
      "Let's start by reading the data from the NREL EUSS Database.\n",
      "\n",
      "Make sure that the zipped folders stay organized as they are once unzipped.\n",
      "If changes are made to the file path, then the program will not run properly.\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "BASELINE (Measure Package 0)\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved data for filename: baseline_metadata_and_annual_results.csv\n",
      "Located at filepath: c:\\Users\\14128\\Research\\cmu-tare-model\\euss_data\\resstock_amy2018_release_1.1\\state\\baseline_metadata_and_annual_results.csv\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Data Filters: Only occupied units and Single Family Homes\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Welcome to the Trade-off Analysis of residential Retrofits for energy Equity Tool (TARE Model)\n",
    "Let's start by reading the data from the NREL EUSS Database.\n",
    "\n",
    "Make sure that the zipped folders stay organized as they are once unzipped.\n",
    "If changes are made to the file path, then the program will not run properly.\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "BASELINE (Measure Package 0)\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "# Measure Package 0: Baseline\n",
    "menu_mp = 0\n",
    "input_mp = 'baseline'\n",
    "\n",
    "filename = \"baseline_metadata_and_annual_results.csv\"\n",
    "relative_path = os.path.join(r\"euss_data\\resstock_amy2018_release_1.1\\state\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Data Filters: Only occupied units and Single Family Homes\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "# Fix DtypeWarning error in columns:\n",
    "# 'in.neighbors', 'in.geometry_stories_low_rise', 'in.iso_rto_region', 'in.pv_orientation', 'in.pv_system_size'\n",
    "columns_to_string = {11: str, 61: str, 121: str, 103: str, 128: str, 129: str}\n",
    "df_euss_am_baseline = pd.read_csv(file_path, dtype=columns_to_string)\n",
    "occupancy_filter = df_euss_am_baseline['in.vacancy_status'] == 'Occupied'\n",
    "df_euss_am_baseline = df_euss_am_baseline.loc[occupancy_filter]\n",
    "\n",
    "# Filter for single family home building type\n",
    "house_type_list = ['Single-Family Attached', 'Single-Family Detached']\n",
    "house_type_filter = df_euss_am_baseline['in.geometry_building_type_recs'].isin(house_type_list)\n",
    "df_euss_am_baseline = df_euss_am_baseline.loc[house_type_filter]\n",
    "# df_euss_am_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df15a84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_menu_choice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Make a copy of the dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# df_euss_am_baseline = df_euss_am_baseline.copy()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Choose between national or sub-national level analysis\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m menu_state \u001b[38;5;241m=\u001b[39m get_menu_choice(menu_prompt, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m})   \u001b[38;5;66;03m# This code is only run in baseline\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# National Level \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m menu_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_menu_choice' is not defined"
     ]
    }
   ],
   "source": [
    "# # Make a copy of the dataframe\n",
    "# df_euss_am_baseline = df_euss_am_baseline.copy()\n",
    "\n",
    "# Choose between national or sub-national level analysis\n",
    "menu_state = get_menu_choice(menu_prompt, {'N', 'Y'})   # This code is only run in baseline\n",
    "\n",
    "# National Level \n",
    "if menu_state == 'N':\n",
    "    print(\"You chose to analyze all of the United States.\")\n",
    "    input_state = 'National'\n",
    "\n",
    "# Filter down to state or city\n",
    "else:\n",
    "    input_state = get_state_choice(df_euss_am_baseline)\n",
    "    print(f\"You chose to filter for: {input_state}\")\n",
    "    state_filter = df_euss_am_baseline['in.state'].eq(input_state)\n",
    "    df_euss_am_baseline = df_euss_am_baseline.loc[state_filter]\n",
    "\n",
    "    print(city_prompt)\n",
    "    print(df_euss_am_baseline['in.city'].value_counts())\n",
    "\n",
    "    menu_city = get_menu_choice(city_menu_prompt, {'N', 'Y'})\n",
    "\n",
    "    # Filter for the entire selected state\n",
    "    if menu_city == 'N':\n",
    "        print(f\"You chose to analyze all of state: {input_state}\")\n",
    "        \n",
    "    # Filter to a city within the selected state\n",
    "    else:\n",
    "        input_cityFilter = get_city_choice(df_euss_am_baseline, input_state)\n",
    "        print(f\"You chose to filter for: {input_state}, {input_cityFilter}\")\n",
    "        city_filter = df_euss_am_baseline['in.city'].eq(f\"{input_state}, {input_cityFilter}\")\n",
    "        df_euss_am_baseline = df_euss_am_baseline.loc[city_filter]\n",
    "\n",
    "# Display the filtered dataframe\n",
    "df_euss_am_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a96352",
   "metadata": {},
   "source": [
    "## Baseline Energy Consumption\n",
    "### Factors to Project Future Energy Consumption Using EIA Heating Degree Day (HDD) Forecasted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de961516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factors for 2018 to 2050\n",
    "filename = 'aeo_projections_2022_2050.xlsx'\n",
    "relative_path = os.path.join(r\"projections\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_hdd_projection_factors = pd.read_excel(io=file_path, sheet_name='hdd_factors_2018_2050')\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "# Convert the factors dataframe into a lookup dictionary\n",
    "hdd_factor_lookup = df_hdd_projection_factors.set_index(['census_division']).to_dict('index')\n",
    "hdd_factor_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Baseline Consumption:\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "# df_baseline_enduse(df_baseline, df_enduse, category, fuel_filter='Yes', tech_filter='Yes')\n",
    "df_euss_am_baseline_home = df_enduse_refactored(df_baseline = df_euss_am_baseline,\n",
    "                                                fuel_filter = 'Yes',\n",
    "                                                tech_filter = 'Yes')\n",
    "\n",
    "# Project Future Energy Consumption\n",
    "df_euss_am_baseline_home = project_future_consumption(df=df_euss_am_baseline_home, hdd_factor_lookup=hdd_factor_lookup, menu_mp=menu_mp)\n",
    "df_euss_am_baseline_home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8ac2dc",
   "metadata": {},
   "source": [
    "## Factors to Project Future Energy Consumption Using EIA Heating Degree Day (HDD) Forecasted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b8ae9",
   "metadata": {
    "id": "APZVHBCeV-mP"
   },
   "source": [
    "## Public Perspective: Monetized Marginal Damages from Emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac2cf15",
   "metadata": {
    "id": "LPmgxqAfV-mh"
   },
   "source": [
    "### Step 1: Calculate emissions factors for different fuel sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16754aff",
   "metadata": {
    "id": "ccY7_aZnV-mh"
   },
   "source": [
    "### Marginal Emissions Factors\n",
    "#### Electricity\n",
    "- STATE Regional Aggregation is what is used in the Parth Analysis \n",
    "- \"Marginal Emissions Factors for Electricity\"\n",
    "- Factor Type: Marginal\n",
    "- Calculation Method: Regression\n",
    "- Metric: Emissions [kg/MWh]\")\n",
    "- Predictor: Year\")\n",
    "- Pollutants: SO2, NOx, PM2.5, CO2\")\n",
    "#### Fossil Fuels\n",
    "- NOx, SO2, CO2: \n",
    "    - RESNET Table 7.1.2 Emissions Factors for Household Combustion Fuels\n",
    "    - Source: https://www.resnet.us/wp-content/uploads/ANSIRESNETICC301-2022_resnetpblshd.pdf\n",
    "    - All factors are in units of lb/Mbtu so energy consumption in kWh need to be converted to kWh \n",
    "    - (1 lb / Mbtu) * (1 Mbtu / 1x10^6 Btu) * (3412 Btu / 1 kWh)\n",
    "- PM2.5: \n",
    "    - A National Methodology and Emission Inventory for Residential Fuel Combustion\n",
    "    - Source: https://www3.epa.gov/ttnchie1/conference/ei12/area/haneke.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8670a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Public Perspective: Monetized Marginal Damages from Emissions\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Step 1: Calculate emissions factors for different fuel sources\n",
    "- Electricity\n",
    "- Natural Gas\n",
    "- Fuel Oil \n",
    "- Propane\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc87933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Calculate Emissions Factors: ELECTRICITY\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Electricity Marginal Emissions Factors:\n",
    "- STATE Regional Aggregation is what is used in the Parth Analysis \n",
    "- \"Marginal Emissions Factors for Electricity\"\n",
    "- Factor Type: Marginal\n",
    "- Calculation Method: Regression\n",
    "- Metric: Emissions [kg/MWh]\n",
    "- Predictor: Year\")\n",
    "- Pollutants: SO2, NOx, PM2.5, CO2\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "filename = 'Generation-MARREG-EMIT-state-byYear.csv'\n",
    "relative_path = os.path.join(r\"margEmis_electricity\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_margEmissions = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# Convert from kg/MWh to lb/kWh\n",
    "# Obtain value from the CSV file and convert to lbs pollutant per kWh \n",
    "df_margEmis_electricity = pd.DataFrame({\n",
    "    'state': df_margEmissions['region'],\n",
    "    'fuel_type': 'electricity',\n",
    "    'pollutant': df_margEmissions['pollutant'],\n",
    "    'value': df_margEmissions['factor'] * (2.20462/1) * (1/1000),\n",
    "    'unit': '[lb/kWh]'\n",
    "})\n",
    "df_margEmis_electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2160b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Calculate Emissions Factors: FOSSIL FUELS\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Fossil Fuels (Natural Gas, Fuel Oil, Propane):\n",
    "- NOx, SO2, CO2: \n",
    "    - RESNET Table 7.1.2 Emissions Factors for Household Combustion Fuels\n",
    "    - Source: https://www.resnet.us/wp-content/uploads/ANSIRESNETICC301-2022_resnetpblshd.pdf\n",
    "    - All factors are in units of lb/Mbtu so energy consumption in kWh need to be converted to kWh \n",
    "    - (1 lb / Mbtu) * (1 Mbtu / 1x10^6 Btu) * (3412 Btu / 1 kWh)\n",
    "- PM2.5: \n",
    "    - A National Methodology and Emission Inventory for Residential Fuel Combustion\n",
    "    - Source: https://www3.epa.gov/ttnchie1/conference/ei12/area/haneke.pdf\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "fuelOil_factors = calculate_fossilFuel_emission_factor(\"fuelOil\", 0.0015, 0.1300, 0.83, 161.0, 1000, 138500)\n",
    "naturalGas_factors = calculate_fossilFuel_emission_factor(\"naturalGas\", 0.0006, 0.0922, 1.9, 117.6, 1000000, 1039)\n",
    "propane_factors = calculate_fossilFuel_emission_factor(\"propane\", 0.0002, 0.1421, 0.17, 136.6, 1000, 91452)\n",
    "\n",
    "all_factors = {**fuelOil_factors, **naturalGas_factors, **propane_factors}\n",
    "\n",
    "df_margEmis_factors = pd.DataFrame.from_dict(all_factors, orient=\"index\", columns=[\"value\"])\n",
    "df_margEmis_factors.reset_index(inplace=True)\n",
    "df_margEmis_factors.columns = [\"pollutant\", \"value\"]\n",
    "df_margEmis_factors[[\"fuel_type\", \"pollutant\"]] = df_margEmis_factors[\"pollutant\"].str.split(\"_\", expand=True)\n",
    "df_margEmis_factors[\"unit\"] = \"[lb/kWh]\"\n",
    "\n",
    "# Add the 'state' column and assign 'National' to every row\n",
    "df_margEmis_factors = df_margEmis_factors.assign(state='National')\n",
    "\n",
    "df_margEmis_factors = df_margEmis_factors[[\"state\", \"fuel_type\", \"pollutant\", \"value\", \"unit\"]]\n",
    "df_margEmis_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef1867",
   "metadata": {},
   "source": [
    "### Step 2: Adjust Natural Gas & Electricity Emissions Factors for Natural Gas Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d4c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Step 2: Adjust Natural Gas & Electricity Emissions Factors for Natural Gas Leakage\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Natural Gas (Deetjen et al.): \n",
    "\"To account for the natural gas infrastructure's leakage of the greenhouse gas methane, \n",
    "we estimate the amount of methane leaked per therm of natural gas consumed for heating and \n",
    "convert to CO2-equivalent emissions via the GWP of methane. We assume that for every therm of \n",
    "natural gas consumed for heating, 0.023 therms of methane escape to the atmosphere [28]. \n",
    "Using the energy density of natural gas, we convert from therms to kilograms and multiply \n",
    "by 28—the GWP of methane [29]—to calculate a rate of 1.27 kg CO2-equivalent per therm of \n",
    "consumed natural gas.\"\n",
    "\n",
    "Electricity NERC Regions (Deetjen et al): \n",
    "\"To account for the natural gas infrastructure's leakage of the greenhouse gas methane, \n",
    "we estimate the amount of methane leaked per MWh of electricity generation in each NERC \n",
    "region and convert to CO2-equivalent emissions via the global warming potential (GWP) of methane. \n",
    "For example, we find that in 2017, the states comprising the western region (WECC) of \n",
    "the US electric grid consumed 1.45 million MMcf of natural gas in the power sector [27]. \n",
    "We assume that for every MMcf of consumed natural gas, 0.023 MMcf of methane is leaked into \n",
    "the atmosphere [28]. By multiplying that leakage rate by the 1.45 million MMcf of consumed \n",
    "natural gas, converting to tonnes, and multiplying by a GWP of 28 [29], we estimate \n",
    "that the 2017 WECC power sector contributed to methane leakage amounting to 18.6 Mt CO2-equivalent.\n",
    "By dividing this 18.6 Mt by the 724 TWh of the WECC states' generated electricity [27], we \n",
    "calculate a methane leakage rate factor of 25.7 kg MWh−1. In the same manner, we calculate the \n",
    "methane leakage rate factors for the other NERC regions. We use the 100 years GWP value of 28 \n",
    "for methane. Although there have been proposals to use 20 years GWP values, recent research \n",
    "shows that the benefits of this alternative 20 years time from are overstated [30].\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "filename = 'natural_gas_leakage_rate.csv'\n",
    "relative_path = os.path.join(r\"margEmis_electricity\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_naturalGas_leakage_rate = pd.read_csv(file_path)\n",
    "\n",
    "state_abbreviations = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# Map full state names to abbreviations\n",
    "df_naturalGas_leakage_rate['state'] = df_naturalGas_leakage_rate['state_name'].map(state_abbreviations)\n",
    "\n",
    "# thousand Mcf * (0.023 Mcf leak/1 Mcf) * (19.3 tonnes/1000 Mcf) * (1000 kg/1 tonne) * (2.205 lb/1 kg)) / (thousand MWh * (1000 MWh/thousand MWh)) \n",
    "df_naturalGas_leakage_rate['naturalGas_leakage_lbCH4_perMWh'] = (df_naturalGas_leakage_rate['naturalGas_electricity_generation'] * (0.023/1) * (19.3/1) * (1000/1) * (2.205/1)) / (df_naturalGas_leakage_rate['net_generation'] * (1000/1)) \n",
    "\n",
    "# (lb CH4/MWh) * (28 lb CO2e/1 lb CH4)\n",
    "df_naturalGas_leakage_rate['naturalGas_leakage_lbCO2e_perMWh'] = df_naturalGas_leakage_rate['naturalGas_leakage_lbCH4_perMWh'] * (28/1)\n",
    "\n",
    "# (lb CO2e/MWh) * (1 MWh / 1000 kWh)\n",
    "df_naturalGas_leakage_rate['naturalGas_leakage_lbCO2e_perkWh'] = df_naturalGas_leakage_rate['naturalGas_leakage_lbCO2e_perMWh'] * (1/1000)\n",
    "df_naturalGas_leakage_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd6b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NATURAL GAS LEAKAGE: NATURAL GAS USED IN ELECTRICITY GENERATION\n",
    "if 'naturalGas_leakage_lbCO2e_perkWh' in df_margEmis_electricity.columns:\n",
    "    df_margEmis_electricity.drop(columns=['naturalGas_leakage_lbCO2e_perkWh'], inplace=True)\n",
    "\n",
    "df_margEmis_electricity = df_margEmis_electricity.merge(\n",
    "    df_naturalGas_leakage_rate[['state', 'naturalGas_leakage_lbCO2e_perkWh']],\n",
    "    how='left',  # Use a left join to keep all rows from df_margEmis_electricity\n",
    "    on=['state']  # Merge on the 'state' column\n",
    ")\n",
    "# Set 'naturalGas_leakage_lbCO2e_perkWh' to zero where 'pollutant' is not 'co2'\n",
    "df_margEmis_electricity.loc[df_margEmis_electricity['pollutant'] != 'co2', 'naturalGas_leakage_lbCO2e_perkWh'] = 0.0\n",
    "\n",
    "# Calculate adjusted marginal emissions factore with natural gas fugitive emissions\n",
    "df_margEmis_electricity['margEmis_factor_adjusted'] = df_margEmis_electricity['value'] + df_margEmis_electricity['naturalGas_leakage_lbCO2e_perkWh'] \n",
    "\n",
    "# Create a factor to multiply marginal damages by\n",
    "df_margEmis_electricity['naturalGas_leakage_factor'] = df_margEmis_electricity['margEmis_factor_adjusted'] / df_margEmis_electricity['value']\n",
    "\n",
    "# Reorder columns\n",
    "df_margEmis_electricity = df_margEmis_electricity[['state', 'fuel_type', 'pollutant', 'value', 'unit', 'naturalGas_leakage_lbCO2e_perkWh', 'margEmis_factor_adjusted', 'naturalGas_leakage_factor']]\n",
    "df_margEmis_electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb77262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURAL GAS LEAKAGE: NATURAL GAS INFRASTRUCTURE\n",
    "# leakage rate for natural gas infrastructure\n",
    "# 1 Therm = 29.30 kWh --> 1.27 kg CO2e/therm * (1 therm/29.30 kWh) = 0.043 kg CO2e/kWh = 0.095 lb CO2e/kWh\n",
    "df_margEmis_factors['naturalGas_leakage_lbCO2e_perkWh'] = 0.095\n",
    "\n",
    "# Set 'naturalGas_leakage_lbCO2e_perkWh' to zero where 'pollutant' is not 'co2'\n",
    "df_margEmis_factors.loc[df_margEmis_factors['pollutant'] != 'co2', 'naturalGas_leakage_lbCO2e_perkWh'] = 0.0\n",
    "\n",
    "# Set 'naturalGas_leakage_lbCO2e_perkWh' to zero where 'fuel_type' is not 'naturalGas'\n",
    "df_margEmis_factors.loc[df_margEmis_factors['fuel_type'] != 'naturalGas', 'naturalGas_leakage_lbCO2e_perkWh'] = 0.0\n",
    "\n",
    "# Calculate adjusted marginal emissions factor with natural gas fugitive emissions\n",
    "df_margEmis_factors['margEmis_factor_adjusted'] = df_margEmis_factors['value'] + df_margEmis_factors['naturalGas_leakage_lbCO2e_perkWh'] \n",
    "\n",
    "# Create a factor to multiply marginal damages by\n",
    "df_margEmis_factors['naturalGas_leakage_factor'] = df_margEmis_factors['margEmis_factor_adjusted'] / df_margEmis_factors['value']\n",
    "\n",
    "# Reorder columns\n",
    "df_margEmis_factors = df_margEmis_factors[['state', 'fuel_type', 'pollutant', 'value', 'unit', 'naturalGas_leakage_lbCO2e_perkWh', 'margEmis_factor_adjusted', 'naturalGas_leakage_factor']]\n",
    "df_margEmis_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d032bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Append df_margEmissions_electricity to df_margEmis_factors\n",
    "# This produces a dataframe of marginal emissions rates for various fuel types\n",
    "df_margEmis_factors = pd.concat([df_margEmis_factors, df_margEmis_electricity], ignore_index=True)\n",
    "df_margEmis_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d5e6b",
   "metadata": {},
   "source": [
    "### Step 3: Quantify monitized damages using EASIUR Marginal Social Cost Factors\n",
    "#### THE STEPS BELOW SUMMARIZE WHAT WAS DONE TO OBTAIN ALL NATIONAL EASIUR VALUES INCLUDED ON GITHUB\n",
    "- Obtain all of the dwelling unit latitude and longitude values from the metadata columns\n",
    "- Make a new dataframe of just the longitude and latitude values \n",
    "    - Make sure that the order is (longitude, latitude)\n",
    "    - Do not include the index or column name when exporting \n",
    "- Export the CSV\n",
    "- **Upload csv to EASIUR Website:**\n",
    "    - Website: https://barney.ce.cmu.edu/~jinhyok/easiur/online/\n",
    "    - See inputs in respective sections\n",
    "- Download the file and put it in the 'easiur_batchConversion_download' folder\n",
    "- Copy and paste the name of the file EASIUR generated when prompted\n",
    "- Copy and paste the name of the filepath for the 'easiur_batchConversion_download' folder when prompted\n",
    "- Match up the longitude and latitudes for each dwelling unit with the selected damages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeafea0",
   "metadata": {},
   "source": [
    "### Fossil Fuels: EASIUR Marginal Damage (Social Cost) Factors Info\n",
    "- Factor Type: Marginal Social Cost\n",
    "- Calculation Method: Regression\n",
    "- Metric: Marginal Social Cost [USD per metric ton]\n",
    "- Dollar Year: 2010\n",
    "- Income Year: 2018\n",
    "- Population Year: 2018\n",
    "- Aggregation: Longitude, and Latitude Coordinates\n",
    "- Pollutants: Primary PM2.5, Sulfur Dioxide (SO2), Nitrogen Oxides (NOx), Ammonia (NH3)\n",
    "- Elevation (Ground, 150m, 300m) and Seasons (Winter, Spring, Summer, Fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe containing just the longitude and Latitude\n",
    "df_EASIUR_batchConversion = pd.DataFrame({\n",
    "    'Longitude':df_euss_am_baseline['in.weather_file_longitude'],\n",
    "    'Latitude':df_euss_am_baseline['in.weather_file_latitude'],\n",
    "})\n",
    "\n",
    "# Drop duplicate rows based on 'Longitude' and 'Latitude' columns\n",
    "df_EASIUR_batchConversion.drop_duplicates(subset=['Longitude', 'Latitude'], keep='first', inplace=True)\n",
    "\n",
    "# Create a location ID for the name of the batch conversion file\n",
    "while True:\n",
    "    if menu_state == 'N':\n",
    "        location_id = 'National'\n",
    "        print(\"You chose to analyze all of the United States.\")\n",
    "        break\n",
    "    elif menu_state == 'Y':\n",
    "        if menu_city == 'N':\n",
    "            try:\n",
    "                location_id = str(input_state)\n",
    "                print(f\"Location ID is: {location_id}\")\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input for state!\")\n",
    "        elif menu_city == 'Y':\n",
    "            try:\n",
    "                location_id = input_cityFilter.replace(', ', '_').strip()\n",
    "                print(f\"Location ID is: {location_id}\")\n",
    "                break\n",
    "            except AttributeError:\n",
    "                print(\"Invalid input for city filter!\")\n",
    "        else:\n",
    "            print(\"Incorrect state or city filter assignment!\")\n",
    "    else:\n",
    "        print(\"Invalid data location. Check your inputs at the beginning of this notebook!\")\n",
    "\n",
    "# Updated GitHub code has EASIUR file with all unique latitude, longitude coordinates in the US\n",
    "filename = 'easiur_National2024-06-1420-17.csv'\n",
    "relative_path = os.path.join(r\"margDamages_EASIUR\\easiur_batchConversion_download\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_margSocialCosts = pd.read_csv(file_path)\n",
    "\n",
    "# Convert from kg/MWh to lb/kWh\n",
    "# Obtain value from the CSV file and convert to lbs pollutant per kWh \n",
    "\n",
    "# Define df_margSocialCosts_EASIUR DataFrame first\n",
    "df_margSocialCosts_EASIUR = pd.DataFrame({\n",
    "    'Longitude': df_margSocialCosts['Longitude'],\n",
    "    'Latitude': df_margSocialCosts['Latitude']\n",
    "})\n",
    "df_margSocialCosts_EASIUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518cb848",
   "metadata": {},
   "source": [
    "### Step 4: Inflate Marginal Social Cost (Damage) Factors using BLS CPI for All Urban Consumers (CPI-U)\n",
    "- Series Id:\tCUUR0000SA0\n",
    "- Not Seasonally Adjusted\n",
    "- Series Title:\tAll items in U.S. city average, all urban consumers, not seasonally adjusted\n",
    "- Area:\tU.S. city average\n",
    "- Item:\tAll items\n",
    "- Base Period:\t1982-84=100\n",
    "\n",
    "### Use the updated Social Cost of Carbon (190 USD-2020/ton CO2) and inflate to USD-2023\n",
    "- EPA Median for 2% near term discount rate and most commonly mentioned value is 190 USD-2020 using the GIVE model.\n",
    "- 190 USD-2020 has some inconsistency with the VSL being used. An old study and 2008 VSL is noted\n",
    "- 190 USD value and inflate to USD 2023 because there is a clear source and ease of replicability.\n",
    "\n",
    "### Adjustment for VSL\n",
    "- EASIUR uses a VSL of 8.8M USD-2010 \n",
    "- New EPA VSL is 11.3M USD-2021\n",
    "- INFLATE TO $USD-2023\n",
    "\n",
    "### ALL DOLLAR VALUES ARE NOW IN USD2023, PREVIOUSLY USED $USD-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BLS Inflation Data\n",
    "filename = 'bls_cpiu_2005-2023.xlsx'\n",
    "relative_path = os.path.join(r\"inflation_data\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df_bls_cpiu = pd.read_excel(file_path, sheet_name='bls_cpiu')\n",
    "\n",
    "df_bls_cpiu = pd.DataFrame({\n",
    "    'year': df_bls_cpiu['Year'],\n",
    "    'cpiu_annual': df_bls_cpiu['Annual']\n",
    "})\n",
    "\n",
    "# Obtain the Annual CPIU values for the years of interest\n",
    "bls_cpi_annual_2008 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2008)].item()\n",
    "bls_cpi_annual_2010 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2010)].item()\n",
    "bls_cpi_annual_2013 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2013)].item()\n",
    "bls_cpi_annual_2018 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2018)].item()\n",
    "bls_cpi_annual_2019 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2019)].item()\n",
    "bls_cpi_annual_2020 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2020)].item()\n",
    "bls_cpi_annual_2021 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2021)].item()\n",
    "bls_cpi_annual_2022 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2022)].item()\n",
    "bls_cpi_annual_2023 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2023)].item()\n",
    "\n",
    "# Precompute constant values\n",
    "cpi_ratio_2023_2022 = bls_cpi_annual_2023 / bls_cpi_annual_2022\n",
    "cpi_ratio_2023_2021 = bls_cpi_annual_2023 / bls_cpi_annual_2021  # This will be 1\n",
    "cpi_ratio_2023_2020 = bls_cpi_annual_2023 / bls_cpi_annual_2020  # For SCC\n",
    "cpi_ratio_2023_2019 = bls_cpi_annual_2023 / bls_cpi_annual_2019 \n",
    "cpi_ratio_2023_2018 = bls_cpi_annual_2023 / bls_cpi_annual_2018 \n",
    "cpi_ratio_2023_2013 = bls_cpi_annual_2023 / bls_cpi_annual_2013\n",
    "cpi_ratio_2023_2010 = bls_cpi_annual_2023 / bls_cpi_annual_2010\n",
    "cpi_ratio_2023_2008 = bls_cpi_annual_2023 / bls_cpi_annual_2008  # For EPA VSL and SCC\n",
    "\n",
    "# 2021 US EPA VSL is $11.3M in 2021 \n",
    "# INFLATE TO USD2023, PREVIOUSLY USD2021\n",
    "df_margSocialCosts_EASIUR['current_VSL_USD2023'] = 11.3 * cpi_ratio_2023_2021\n",
    "\n",
    "# Easiur uses a VSL of $8.8 M USD2010\n",
    "# Inflate to 2023 $USD\n",
    "# PREVIOUSLY USD2021\n",
    "df_margSocialCosts_EASIUR['easiur_VSL_USD2023'] = 8.8 * cpi_ratio_2023_2010\n",
    "\n",
    "# Use df_margSocialCosts_EASIUR in the calculation of other columns\n",
    "# Also adjust the VSL\n",
    "df_margSocialCosts_EASIUR['margSocialCosts_pm25'] = round((df_margSocialCosts['PM25 Annual Ground'] * (1/2204.6) * (df_margSocialCosts_EASIUR['current_VSL_USD2023']/df_margSocialCosts_EASIUR['easiur_VSL_USD2023'])), 2)\n",
    "df_margSocialCosts_EASIUR['margSocialCosts_so2'] = round((df_margSocialCosts['SO2 Annual Ground'] * (1/2204.6) * (df_margSocialCosts_EASIUR['current_VSL_USD2023']/df_margSocialCosts_EASIUR['easiur_VSL_USD2023'])), 2)\n",
    "df_margSocialCosts_EASIUR['margSocialCosts_nox'] = round((df_margSocialCosts['NOX Annual Ground'] * (1/2204.6) * (df_margSocialCosts_EASIUR['current_VSL_USD2023']/df_margSocialCosts_EASIUR['easiur_VSL_USD2023'])), 2)\n",
    "\n",
    "# Note that SCC of $190 USD-2020 has some inconsistency with the VSL being used. An old study and 2008 VSL is noted\n",
    "# We use the $190 USD value and inflate to USD 2023 because there is a clear source and ease of replicability.\n",
    "# PREVIOUSLY USED USD2021\n",
    "df_margSocialCosts_EASIUR['margSocialCosts_co2'] = round((190 * cpi_ratio_2023_2020 * (1/2204.6)), 2)\n",
    "df_margSocialCosts_EASIUR['unit'] = '[$USD2023/lb]'\n",
    "df_margSocialCosts_EASIUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e7ab0",
   "metadata": {},
   "source": [
    "## Electricity CEDM-EASIUR Marginal Damages: Current and Decarbonizing Grid\n",
    "- Factor Type: Marginal\n",
    "- Calculation Method: Regression\n",
    "- Metric: Marginal Damages EASIUR [USD per MWh or kWh]\n",
    "- Year: 2018\n",
    "- Regional Aggregation: eGRID subregion (all regions)\n",
    "- Pollutants: SO2, NOx, PM2.5 CO2\n",
    "\n",
    "SCC Adjustment: We use the EPA suggested 190 USD-2020 value for the social cost of carbon and inflate to 2023 USD. **PREVIOUSLY USED 2021 USD**\n",
    "\n",
    "VSL: \"We use a value of a statistical life (VSL) of USD 8.8 million (in 2010 dollars) for both our AP2 and EASIUR calculations. EASIUR reports damage intensities in USD/metric ton using this VSL and dollar year.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ce15e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For CO2 adjust SCC\n",
    "# Create an adjustment factor for the new Social Cost of Carbon (SCC)\n",
    "epa_scc = 190 * cpi_ratio_2023_2020\n",
    "old_scc = 40 * cpi_ratio_2023_2010\n",
    "scc_adjustment_factor = epa_scc / old_scc\n",
    "\n",
    "# For Health-Related Emissions Adjust for different Value of a Statistical Life (VSL) values\n",
    "# Current VSL is $11.3 M USD2021\n",
    "# INFLATE TO USD2023, PREVIOUSLY USD2021\n",
    "current_VSL_USD2023 = 11.3 * cpi_ratio_2023_2021\n",
    "\n",
    "# Easiur uses a VSL of $8.8 M USD2010\n",
    "# INFLATE TO USD2023, PREVIOUSLY USD2021\n",
    "easiur_VSL_USD2023 = 8.8 * (cpi_ratio_2023_2010)\n",
    "\n",
    "# Calculate VSL adjustment factor\n",
    "vsl_adjustment_factor = current_VSL_USD2023 / easiur_VSL_USD2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e5cac",
   "metadata": {},
   "source": [
    "### Damages from Climate Related Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e7a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate damages (co2) are expected to decline 68% linearlly by 2030 (% relative to 2005)\n",
    "# Note only 2006 data available, used in place of 2005\n",
    "filename = 'Generation-MARREG-DAMEASIUR-egrid-byYear_climate2006.csv'\n",
    "relative_path = os.path.join(r\"margDamages_EASIUR\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_margDamages_climate2006 = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate damages (co2) are expected to decline 68% linearlly by 2030 (% relative to 2005)\n",
    "# Note 2018 start year\n",
    "filename = 'Generation-MARREG-DAMEASIUR-egrid-byYear_climate2018.csv'\n",
    "relative_path = os.path.join(r\"margDamages_EASIUR\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_margDamages_climate2018 = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal damages [$/kWh]\n",
    "# Inflate from 2010 to 2023\n",
    "# PREVIOUSLY USED $USD-2021\n",
    "# Note only 2006 data available, used in place of 2005\n",
    "df_margDamages_EASIUR_climate = pd.DataFrame({\n",
    "    'subregion_eGRID': df_margDamages_climate2006['region'],\n",
    "    'pollutant': df_margDamages_climate2006['pollutant'],\n",
    "    'unit': '[$/kWh]',\n",
    "    '2030_decarb': '68% from 2005',\n",
    "    'margDamages_dollarPerkWh_adjustVSL_ref': (df_margDamages_climate2006['factor'] * (scc_adjustment_factor) * (1/1000)) * (cpi_ratio_2023_2010),\n",
    "    'margDamages_dollarPerkWh_adjustVSL_2018': (df_margDamages_climate2018['factor'] * (scc_adjustment_factor) * (1/1000)) * (cpi_ratio_2023_2010)\n",
    "})\n",
    "df_margDamages_EASIUR_climate['margDamages_decarb_2030'] = df_margDamages_EASIUR_climate['margDamages_dollarPerkWh_adjustVSL_ref'] - (df_margDamages_EASIUR_climate['margDamages_dollarPerkWh_adjustVSL_ref'] * 0.68)\n",
    "df_margDamages_EASIUR_climate['reduction_margDamages_2030'] = df_margDamages_EASIUR_climate['margDamages_dollarPerkWh_adjustVSL_2018'] - df_margDamages_EASIUR_climate['margDamages_decarb_2030']\n",
    "df_margDamages_EASIUR_climate['reduction_margDamages_annual'] = df_margDamages_EASIUR_climate['reduction_margDamages_2030'] / 12 # Relative to 2018, \n",
    "# df_margDamages_EASIUR_climate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5120b5",
   "metadata": {},
   "source": [
    "### Damages from Health Related Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9884cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health damages (SO2, NOx, PM2.5) are expected to decline 65% by 2030 (% relative from 2021)\n",
    "filename = 'Generation-MARREG-DAMEASIUR-egrid-byYear_health2018.csv'\n",
    "relative_path = os.path.join(r\"margDamages_EASIUR\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_margDamages_health2018 = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be06df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal damages [$/kWh]\n",
    "# Inflate from 2010 to 2023\n",
    "# PREVIOUSLY USED $USD-2021\n",
    "# Note only 2018 data available, used in place of 2021\n",
    "df_margDamages_EASIUR_health = pd.DataFrame({\n",
    "    'subregion_eGRID': df_margDamages_health2018['region'],\n",
    "    'pollutant': df_margDamages_health2018['pollutant'],\n",
    "    'unit': '[$/kWh]',\n",
    "    '2030_decarb': '65% from 2021',\n",
    "    'margDamages_dollarPerkWh_adjustVSL_ref': (df_margDamages_health2018['factor'] * (vsl_adjustment_factor) * (1/1000)) * (cpi_ratio_2023_2010),\n",
    "    'margDamages_dollarPerkWh_adjustVSL_2018': (df_margDamages_health2018['factor'] * (vsl_adjustment_factor) * (1/1000)) * (cpi_ratio_2023_2010)\n",
    "})\n",
    "df_margDamages_EASIUR_health['margDamages_decarb_2030'] = df_margDamages_EASIUR_health['margDamages_dollarPerkWh_adjustVSL_ref'] - (df_margDamages_EASIUR_health['margDamages_dollarPerkWh_adjustVSL_ref'] * 0.65)\n",
    "df_margDamages_EASIUR_health['reduction_margDamages_2030'] = df_margDamages_EASIUR_health['margDamages_dollarPerkWh_adjustVSL_2018'] - df_margDamages_EASIUR_health['margDamages_decarb_2030']\n",
    "df_margDamages_EASIUR_health['reduction_margDamages_annual'] = df_margDamages_EASIUR_health['reduction_margDamages_2030'] / 9\n",
    "# df_margDamages_EASIUR_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36515649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine them top to bottom\n",
    "df_margDamages_EASIUR = pd.concat([df_margDamages_EASIUR_climate, df_margDamages_EASIUR_health], ignore_index=True)\n",
    "df_margDamages_EASIUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b42bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marginal Damages for a Gradually Decarbonizing Grid\n",
    "df_margDamages_gridDecarb = df_margDamages_EASIUR.copy()\n",
    "\n",
    "years = list(range(2018, 2050))\n",
    "\n",
    "# Apply reductions\n",
    "for year in years:\n",
    "    column_name = f'margDamages_dollarPerkWh_adjustVSL_{year}'\n",
    "    df_margDamages_gridDecarb[column_name] = df_margDamages_gridDecarb['margDamages_dollarPerkWh_adjustVSL_ref']  # Initialize\n",
    "\n",
    "    for index, row in df_margDamages_gridDecarb.iterrows():  # Correctly unpack the index and row\n",
    "        if year <= 2030:\n",
    "            if year == 2018:\n",
    "                df_margDamages_gridDecarb.at[index, column_name] = df_margDamages_gridDecarb.at[index, f'margDamages_dollarPerkWh_adjustVSL_2018']\n",
    "            \n",
    "            # Climate reduction (C02) applicable from 2019 to 2030\n",
    "            # No Health reductions before 2022\n",
    "            if 2019 <= year < 2022:\n",
    "                if row['pollutant'] == 'co2':\n",
    "                    df_margDamages_gridDecarb.at[index, column_name] = df_margDamages_gridDecarb.at[index, f'margDamages_dollarPerkWh_adjustVSL_{year-1}'] - df_margDamages_gridDecarb.at[index, 'reduction_margDamages_annual']\n",
    "                else:\n",
    "                    df_margDamages_gridDecarb.at[index, column_name] = df_margDamages_gridDecarb.at[index, f'margDamages_dollarPerkWh_adjustVSL_{year-1}']\n",
    "            \n",
    "            # Health reduction applicable from 2022 to 2030\n",
    "            # Climate reductions continue\n",
    "            elif year >= 2022:\n",
    "                df_margDamages_gridDecarb.at[index, column_name] = df_margDamages_gridDecarb.at[index, f'margDamages_dollarPerkWh_adjustVSL_{year-1}'] - df_margDamages_gridDecarb.at[index, 'reduction_margDamages_annual']\n",
    "\n",
    "        # Post-2030, damage values should be at the 2030 level\n",
    "        else:\n",
    "            df_margDamages_gridDecarb.at[index, column_name] = df_margDamages_gridDecarb.at[index, f'margDamages_dollarPerkWh_adjustVSL_2030']\n",
    "\n",
    "df_margDamages_gridDecarb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a96e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the lookup data\n",
    "dict_margDamages_gridDecarb = {}\n",
    "\n",
    "for year in years:\n",
    "    # Create an empty dictionary for the current year\n",
    "    year_lookup = {}\n",
    "    \n",
    "    for _, row in df_margDamages_gridDecarb.iterrows():\n",
    "        year_lookup[(row['subregion_eGRID'], row['pollutant'])] = row[f'margDamages_dollarPerkWh_adjustVSL_{str(year)}']\n",
    "    \n",
    "    # Add the year-specific lookup to the main lookup_data dictionary\n",
    "    dict_margDamages_gridDecarb[year] = year_lookup\n",
    "\n",
    "# Now, you have a lookup_data dictionary containing emissions factors for each state and year\n",
    "dict_margDamages_gridDecarb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a16f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Calculate Emissions Factors: FOSSIL FUELS\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "# Create a lookup dictionary for the national emissions factors\n",
    "national_factors = df_margEmis_factors[df_margEmis_factors['state'] == 'National']\n",
    "national_lookup = {(row['fuel_type'], row['pollutant']): row['margEmis_factor_adjusted'] for _, row in national_factors.iterrows()}\n",
    "\n",
    "# Create a lookup dictionary for the state-specific emissions factors for electricity\n",
    "electricity_factors = df_margEmis_factors[df_margEmis_factors['fuel_type'] == 'electricity']\n",
    "electricity_lookup = {(row['pollutant'], row['state']): row['margEmis_factor_adjusted'] for _, row in electricity_factors.iterrows()}\n",
    "\n",
    "pollutants = ['so2', 'nox', 'pm25', 'co2']\n",
    "\n",
    "# ELECTRICITY CEDM DAMAGES LOOKUP\n",
    "damages_CEDM_lookup = {(row['pollutant'], row['subregion_eGRID']): row['margDamages_dollarPerkWh_adjustVSL_ref'] for _, row in df_margDamages_EASIUR.iterrows()}\n",
    "\n",
    "# FOSSIL FUELS DAMAGES LOOKUP\n",
    "# Create a damages_fossilFuel_lookup dictionary from df_margSocialCosts_EASIUR\n",
    "damages_fossilFuel_lookup = df_margSocialCosts_EASIUR.groupby(['Longitude', 'Latitude']).first().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06128e",
   "metadata": {},
   "source": [
    "### Step 5: Calculate End-use specific marginal damages\n",
    "**I used the total emissions column for each of the end uses for the following reasons:**\n",
    "- Most homes only have 1 of each end-use, so it is unlikely that the homes have a significant consumption values from different fuel types. Thus, the total consumption and total emissions column (sum of each dwelling units consumption by end-use for each fuel) is fine to use to calculate marginal damages (social cost)\n",
    "- We can visualize the emissions in 2 by 2 grid (CO2, PM25, SO2, NOx) with each appliance's heating fuel in a different shape or color. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fe131",
   "metadata": {},
   "source": [
    "### Baseline Marginal Damages: WHOLE-HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Step 5: Calculate End-use specific marginal damages\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "      \n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Baseline Marginal Damages: WHOLE-HOME\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "# calculate_marginal_damages(df, grid_decarb=False)\n",
    "df_euss_am_baseline_home = calculate_marginal_damages(df=df_euss_am_baseline_home,\n",
    "                                                      grid_decarb=False,\n",
    "                                                     )\n",
    "df_euss_am_baseline_home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50814aa1",
   "metadata": {
    "id": "jiGPU0RCV-mQ"
   },
   "source": [
    "## Private Perspective: Annual Energy Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe910a65",
   "metadata": {},
   "source": [
    "### Step 1: Obtain Level Energy Fuel Cost Data from the EIA\n",
    "**Data Sources for Excel workbook containing state average Residential fuel cost for each fuel in 2018**\n",
    "- EIA State Electricity Price: https://www.eia.gov/electricity/state/archive/2018/\n",
    "- EIA Natural Gas Prices: https://www.eia.gov/dnav/ng/ng_pri_sum_dcu_SPA_a.htm\n",
    "- Propane and Fuel Oil: EIA March 2023 Short Term Energy Outlook\n",
    "    - https://www.eia.gov/outlooks/steo/pdf/wf01.pdf\n",
    "    - Table WF01: Average Consumer Prices and Expenditures for Heating Fuels During the Winter\n",
    "    - US Average: 2018-2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7facc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Private Perspective: Annual Energy Costs\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "- Step 1: Obtain Level Energy Fuel Cost Data from the EIA\n",
    "- Step 2: Calculate Annual Operating (Fuel) Costs\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "      \n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Step 1: Obtain Level Energy Fuel Cost Data from the EIA\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "**Data Sources for Excel workbook containing state average Residential fuel cost for each fuel in 2018**\n",
    "- EIA State Electricity Price: https://www.eia.gov/electricity/state/archive/2018/\n",
    "- EIA Natural Gas Prices: https://www.eia.gov/dnav/ng/ng_pri_sum_dcu_SPA_a.htm\n",
    "- Propane and Fuel Oil: EIA March 2023 Short Term Energy Outlook\n",
    "    - https://www.eia.gov/outlooks/steo/pdf/wf01.pdf\n",
    "    - Table WF01: Average Consumer Prices and Expenditures for Heating Fuels During the Winter\n",
    "    - US Average: 2018-2019 Data\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "\n",
    "filename = 'fuel_prices_nominal.csv'\n",
    "relative_path = os.path.join(r\"fuel_prices\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_fuelPrices_perkWh = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "# New units for the converted and inflated prices below\n",
    "# $USD-2023, PREVIOUSLY USED $USD-2021\n",
    "df_fuelPrices_perkWh['units'] = 'USD2023 per kWh'\n",
    "\n",
    "years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "# Take dataframe with nominal prices in their base units and convert to $/kWh equivalent\n",
    "# https://www.eia.gov/energyexplained/units-and-calculators/british-thermal-units.php\n",
    "for year in years:\n",
    "    for index, row in df_fuelPrices_perkWh.iterrows():\n",
    "        \n",
    "        # Propane: (dollars per gallon) * (1 gallon propane/91,452 BTU) * (3412 BTU/1 kWh)\n",
    "        if row['fuel_type'] == 'propane':\n",
    "            df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/91452) * (3412/1)\n",
    "        \n",
    "        # Fuel Oil: (dollars/gallon) * (1 gallon heating oil/138,500 BTU) * (3412 BTU/1 kWh)\n",
    "        elif row['fuel_type'] == 'fuelOil':\n",
    "            df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/138500) * (3412/1)\n",
    "        \n",
    "        # Natural Gas: (dollars/cf) * (thousand cf/1000 cf) * (1 cf natural gas/1039 BTU) * (3412 BTU/1 kWh)\n",
    "        elif row['fuel_type'] == 'naturalGas':\n",
    "            df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/1000) * (1/1039) * (3412/1)\n",
    "        \n",
    "        # Electricity: convert cents per kWh to $ per kWh\n",
    "        elif row['fuel_type'] == 'electricity':\n",
    "            df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] / 100\n",
    "\n",
    "# Convert nominal dollars to real 2023 US dollars (USD2023)\n",
    "# $USD-2023, PREVIOUSLY USED $USD-2021\n",
    "df_fuelPrices_perkWh['2018_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2018_fuelPrice_perkWh'] * cpi_ratio_2023_2018\n",
    "df_fuelPrices_perkWh['2019_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2019_fuelPrice_perkWh'] * cpi_ratio_2023_2019\n",
    "df_fuelPrices_perkWh['2020_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2020_fuelPrice_perkWh'] * cpi_ratio_2023_2020\n",
    "df_fuelPrices_perkWh['2021_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2021_fuelPrice_perkWh'] * cpi_ratio_2023_2021\n",
    "df_fuelPrices_perkWh['2022_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2022_fuelPrice_perkWh'] * cpi_ratio_2023_2022\n",
    "\n",
    "# Original dictionary mapping census divisions to states\n",
    "map_states_census_divisions = {\n",
    "    \"New England\": [\"CT\", \"ME\", \"MA\", \"NH\", \"RI\", \"VT\"],\n",
    "    \"Middle Atlantic\": [\"NJ\", \"NY\", \"PA\"],\n",
    "    \"East North Central\": [\"IN\", \"IL\", \"MI\", \"OH\", \"WI\"],\n",
    "    \"West North Central\": [\"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"],\n",
    "    \"South Atlantic\": [\"DE\", \"DC\", \"FL\", \"GA\", \"MD\", \"NC\", \"SC\", \"VA\", \"WV\"],\n",
    "    \"East South Central\": [\"AL\", \"KY\", \"MS\", \"TN\"],\n",
    "    \"West South Central\": [\"AR\", \"LA\", \"OK\", \"TX\"],\n",
    "    \"Mountain\": [\"AZ\", \"CO\", \"ID\", \"NM\", \"MT\", \"UT\", \"NV\", \"WY\"],\n",
    "    \"Pacific\": [\"AK\", \"CA\", \"HI\", \"OR\", \"WA\"]\n",
    "}\n",
    "\n",
    "# Reverse the mapping to create a state-to-census-division map\n",
    "state_to_census_division = {}\n",
    "for division, states in map_states_census_divisions.items():\n",
    "    for state in states:\n",
    "        state_to_census_division[state] = division\n",
    "\n",
    "# Function to map location to census division\n",
    "def map_location_to_census_division(location):\n",
    "    if location in state_to_census_division:\n",
    "        return state_to_census_division[location]\n",
    "    return location\n",
    "\n",
    "# Apply the function to map locations using .loc\n",
    "df_fuelPrices_perkWh.loc[:, 'census_division'] = df_fuelPrices_perkWh['location_map'].apply(map_location_to_census_division)\n",
    "df_fuelPrices_perkWh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'fuel_price_projection_factors.csv'\n",
    "relative_path = os.path.join(r\"fuel_prices\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "df_fuelPrices_projection_factors = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "# Convert the factors dataframe into a lookup dictionary\n",
    "factor_dict = df_fuelPrices_projection_factors.set_index(['region', 'fuel_type']).to_dict('index')\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "projected_prices_df = df_fuelPrices_perkWh.apply(lambda row: project_future_prices(row, factor_dict), axis=1)\n",
    "\n",
    "# Concatenate the projected prices with the original DataFrame\n",
    "df_fuelPrices_perkWh_projected = pd.concat([df_fuelPrices_perkWh, projected_prices_df], axis=1)\n",
    "\n",
    "# Create Fuel Price Lookup\n",
    "fuel_price_lookup = create_fuel_price_lookup(df_fuelPrices_perkWh_projected)\n",
    "fuel_price_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec9c48",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Annual Operating (Fuel) Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1f3ab",
   "metadata": {},
   "source": [
    "### Baseline Fuel Cost: WHOLE-HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e19c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "Step 2: Calculate Annual Operating (Fuel) Costs\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "- Create a mapping dictionary for fuel types\n",
    "- Create new merge columns to ensure a proper match.\n",
    "- Merge df_copy with df_fuel_prices to get fuel prices for electricity, natural gas, propane, and fuel oil\n",
    "- Calculate the per kWh fuel costs for each fuel type and region\n",
    "- Calculate the baseline fuel cost \n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\"\"\")\n",
    "# df_euss_am_baseline_home = df_euss_am_baseline_home.copy()\n",
    "# calculate_annual_fuelCost(df, fuel_price_lookup, lifetime)\n",
    "df_euss_am_baseline_home = calculate_annual_fuelCost(df=df_euss_am_baseline_home,\n",
    "                                                     fuel_price_lookup=fuel_price_lookup,\n",
    "                                                     menu_mp=menu_mp\n",
    "                                                     )\n",
    "df_euss_am_baseline_home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d6bc3",
   "metadata": {},
   "source": [
    "### Area Median Income Data Used to determine LMI Designation and IRA Rebates Eligibility/Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Area Median Income Data at PUMA-resolution\n",
    "filename = \"nhgis0002_ds239_20185_puma.csv\"\n",
    "relative_path = os.path.join(r\"equity_data\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_county_medianIncome = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "df_county_medianIncome = df_county_medianIncome.drop(0)\n",
    "df_county_medianIncome = df_county_medianIncome.reset_index(drop=True)\n",
    "\n",
    "cols_interest = ['GISJOIN', 'STUSAB', 'STATE', 'PUMAA', 'GEOID', 'NAME_E', 'AJZAE001', 'AJZAM001']\n",
    "df_county_medianIncome = df_county_medianIncome[cols_interest]\n",
    "df_county_medianIncome = df_county_medianIncome.rename(columns={\"GISJOIN\": \"gis_joinID_puma\", \"STUSAB\": \"state_abbrev\", \"STATE\": \"state\", \"PUMAA\": \"puma_code\", \"GEOID\": \"census_geoID\", \"NAME_E\": \"name_estimate\", \"AJZAE001\": \"median_income_USD2018\", \"AJZAM001\": \"median_income_USD2018_marginOfError\"})\n",
    "df_county_medianIncome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af5ef0f",
   "metadata": {},
   "source": [
    "### Adjustment Factors for Construction: \n",
    "#### RSMeans City Cost Index\n",
    "#### Consumer Price Index for All Urban Consumers (CPI, CPI-U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931eec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust for regional cost differences with RSMeans\n",
    "filename = \"rsMeans_cityCostIndex.csv\"\n",
    "relative_path = os.path.join(r\"inflation_data\", filename)\n",
    "file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "print(f\"Retrieved data for filename: {filename}\")\n",
    "print(f\"Located at filepath: {file_path}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df_rsMeans_cityCostIndex = pd.read_csv(file_path)\n",
    "\n",
    "df_rsMeans_cityCostIndex = pd.DataFrame({\n",
    "    'State': df_rsMeans_cityCostIndex['State'],\n",
    "    'City': df_rsMeans_cityCostIndex['City'],\n",
    "    'Material': (df_rsMeans_cityCostIndex['Material']).round(2),\n",
    "    'Installation': (df_rsMeans_cityCostIndex['Installation']).round(2),\n",
    "    'Average': (df_rsMeans_cityCostIndex['Average']).round(2),\n",
    "})\n",
    "df_rsMeans_cityCostIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59411dc1",
   "metadata": {},
   "source": [
    "# Model Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab00fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current datetime again\n",
    "end_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = datetime.strptime(end_time, \"%Y-%m-%d_%H-%M-%S\") - datetime.strptime(start_time, \"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Format the elapsed time\n",
    "elapsed_seconds = elapsed_time.total_seconds()\n",
    "elapsed_minutes = int(elapsed_seconds // 60)\n",
    "elapsed_seconds = int(elapsed_seconds % 60)\n",
    "\n",
    "# Print the elapsed time\n",
    "print(f\"The code took {elapsed_minutes} minutes and {elapsed_seconds} seconds to execute.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
