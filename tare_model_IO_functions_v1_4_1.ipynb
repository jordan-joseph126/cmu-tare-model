{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resstock_run_annual_metadata(data_folder_file_path, input_mp, previous_data=None, baseline_run=1, upgrade_run=2):\n",
    "    # Have this in a standard format required for my data parsing functions\n",
    "    metadata_dict = dict()\n",
    "    metadata_dict[\"applicable_upgrade\"] = True\n",
    "    \n",
    "    if input_mp == 0:\n",
    "        # csv_file_path = os.path.join(csv_folder_file_path, \"run1\", \"run\", )\n",
    "        json_file_path = os.path.join(data_folder_file_path, f\"run{baseline_run}\", \"run\", \"data_point_out.json\")\n",
    "\n",
    "        # List of required properties\n",
    "\n",
    "        # from data_point_out.json\n",
    "        json_required_properties = {\n",
    "            \"bldg_id\":(\"BuildExistingModel\",\"building_id\"),\n",
    "            \"census_division\":(\"BuildExistingModel\",\"census_division\"),\n",
    "            \"state\":(\"BuildExistingModel\",\"state\"),\n",
    "            \"city\":(\"BuildExistingModel\",\"city\"),\n",
    "            \"puma\":(\"BuildExistingModel\",\"puma\"),\n",
    "            \"county\":(\"BuildExistingModel\",\"county\"),\n",
    "            \"reeds_balancing_area\":(\"BuildExistingModel\",\"reeds_balancing_area\"),\n",
    "            \"income\":(\"BuildExistingModel\",\"income\"),\n",
    "            \"hvac_heating_efficiency\":(\"BuildExistingModel\",\"hvac_heating_efficiency\"),\n",
    "            \"hvac_cooling_type\":(\"BuildExistingModel\",\"hvac_cooling_type\"),\n",
    "            \"hvac_cooling_efficiency\":(\"BuildExistingModel\",\"hvac_cooling_efficiency\"),\n",
    "            \"hvac_has_ducts\":(\"BuildExistingModel\",\"hvac_has_ducts\"),\n",
    "            \"heating_type\":(\"BuildExistingModel\",\"hvac_heating_type_and_fuel\"),\n",
    "            \"base_heating_fuel\":(\"BuildExistingModel\",\"heating_fuel\"),\n",
    "        }\n",
    "\n",
    "        if not os.path.exists(json_file_path):\n",
    "            print(\"Baseline run failed, returning empty row\")\n",
    "            metadata_dict[\"applicable_upgrade\"] = False\n",
    "            metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "            df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "            df_mp = pd.concat([previous_data, df_mp])\n",
    "            return df_mp\n",
    "\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            for k,v in json_required_properties.items():\n",
    "                try:\n",
    "                    metadata_dict[k] = json_data[v[0]][v[1]]\n",
    "                except Exception as e:\n",
    "                    print(f\"couldn't find {k} by indexing {v} from json_data\")\n",
    "\n",
    "        # from results_annual.csv\n",
    "        csv_required_properties = {\n",
    "            \"base_electricity_heating_consumption\":\"End Use: Electricity: Heating (MBtu)\",\n",
    "            \"base_naturalGas_heating_consumption\": \"End Use: Natural Gas: Heating (MBtu)\",\n",
    "            \"base_propane_heating_consumption\":\"End Use: Propane: Heating (MBtu)\",\n",
    "            \"base_fuelOil_heating_consumption\":\"End Use: Fuel Oil: Heating (MBtu)\",\n",
    "            \"base_electricity_cooling_consumption\":\"End Use: Electricity: Cooling (MBtu)\",\n",
    "        }\n",
    "\n",
    "        csv_file_path = os.path.join(data_folder_file_path, f\"run{baseline_run}\", \"run\", \"results_annual.csv\")\n",
    "        \n",
    "\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            print(\"Baseline run failed, returning empty row\")\n",
    "            metadata_dict[\"applicable_upgrade\"] = False\n",
    "            metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "            df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "            df_mp = pd.concat([previous_data, df_mp])\n",
    "            return df_mp\n",
    "\n",
    "        csv_data = pd.read_csv(csv_file_path, header=None)\n",
    "        csv_data = csv_data.set_index(0)\n",
    "        for k,v in csv_required_properties.items():\n",
    "            try:\n",
    "                metadata_dict[k] = csv_data.loc[v].iloc[0] * 293.07107 # convert MMBtu to kWh? or Wh?\n",
    "            except Exception as e:\n",
    "                print(f\"couldn't find {k} by indexing {v} from csv_data\")\n",
    "        metadata_dict[\"baseline_heating_consumption\"] = metadata_dict[\"base_naturalGas_heating_consumption\"] + metadata_dict[\"base_electricity_heating_consumption\"] + metadata_dict[\"base_propane_heating_consumption\"] + metadata_dict[\"base_fuelOil_heating_consumption\"]\n",
    "        metadata_dict[\"baseline_cooling_consumption\"] = metadata_dict[\"base_electricity_cooling_consumption\"]\n",
    "\n",
    "        # # List of required properties\n",
    "        # required_properties = {\n",
    "        #     \"bldg_id\":\"bldg_id\",\n",
    "        #     \"census_division\":\"in.census_division\",\n",
    "        #     \"base_electricity_heating_consumption\":\"out.electricity.heating.energy_consumption.kwh\",\n",
    "        #     \"baseline_heating_consumption\": required_properties[\"base_naturalGas_heating_consumption\"] + required_properties[\"base_electricity_heating_consumption\"],\n",
    "        #     \"state\":\"in.state\",\n",
    "        #     \"reeds_balancing_area\":\"in.reeds_balancing_area\",\n",
    "        #     \"base_naturalGas_heating_consumption\": \"out.natural_gas.heating.energy_consumption.kwh\",\n",
    "        #     \"base_propane_heating_consumption\":\"out.propane.heating.energy_consumption.kwh\",\n",
    "        #     \"income\":\"in.income\",\n",
    "        #     \"hvac_heating_efficiency\":\"in.hvac_heating_efficiency\",\n",
    "        #     \"hvac_cooling_type\":\"in.hvac_cooling_type\",\n",
    "        #     \"hvac_has_ducts\":\"in.hvac_has_ducts\",\n",
    "        #     \"heating_type\":\"in.hvac_heating_type_and_fuel\",\n",
    "        # }\n",
    "\n",
    "    if input_mp != 0:\n",
    "        # print(\"loading data from an upgrade\")\n",
    "        upgrade_json_properties = {\n",
    "            \"bldg_id\":(\"BuildExistingModel\",\"building_id\"),\n",
    "            \"baseline_heating_type\":(\"BuildExistingModel\",\"hvac_heating_type_and_fuel\"),\n",
    "            \"size_heating_system_primary_k_btu_h\":(\"UpgradeCosts\",\"size_heating_system_primary_k_btu_h\"),\n",
    "            \"size_cooling_system_primary_k_btu_h\":(\"UpgradeCosts\",\"size_cooling_system_primary_k_btu_h\"),\n",
    "            \"size_heat_pump_backup_primary_k_btu_h\":(\"UpgradeCosts\",\"size_heat_pump_backup_primary_k_btu_h\"),\n",
    "            \"size_heating_system_secondary_k_btu_h\":(\"UpgradeCosts\",\"size_heating_system_secondary_k_btu_h\"),\n",
    "            \"upgrade_hvac_heating_efficiency\":(\"BuildExistingModel\",\"hvac_heating_efficiency\"),\n",
    "        }\n",
    "\n",
    "        json_file_path = os.path.join(data_folder_file_path, f\"run{upgrade_run}\", \"run\", \"data_point_out.json\")\n",
    "        # print(json_file_path)\n",
    "\n",
    "        if not os.path.exists(json_file_path):\n",
    "            print(\"Upgrade not applicable, returning empty row\")\n",
    "            metadata_dict[\"applicable_upgrade\"] = False\n",
    "            metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "            df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "            df_mp = pd.concat([previous_data, df_mp])\n",
    "            return df_mp\n",
    "\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            # json_data[\"UpgradeCosts\"][\"applicable\"] and print(\"Testing upgrade\")\n",
    "            #  = json_data[\"UpgradeCosts\"][\"applicable\"]\n",
    "            if \"UpgradeCosts\" not in json_data.keys() or json_data[\"UpgradeCosts\"][\"applicable\"] != True:\n",
    "                print(\"Upgrade not applicable, returning empty row\")\n",
    "                metadata_dict[\"applicable_upgrade\"] = False\n",
    "                metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "                df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "                df_mp = pd.concat([previous_data, df_mp])\n",
    "                return df_mp\n",
    "            #     raise Exception(\"This upgrade does not apply to this building\")\n",
    "            for k,v in upgrade_json_properties.items():\n",
    "                try:\n",
    "                    metadata_dict[k] = json_data[v[0]][v[1]]\n",
    "                except Exception as e:\n",
    "                    print(f\"couldn't find {k} by indexing {v} from json_data\")\n",
    "\n",
    "        upgrade_csv_properties = {\n",
    "            \"upgrade_natgas_heating_consumption\":\"End Use: Natural Gas: Heating (MBtu)\",\n",
    "            \"upgrade_electricity_heating_consumption\":\"End Use: Electricity: Heating (MBtu)\",\n",
    "            \"upgrade_electricity_cooling_consumption\":\"End Use: Electricity: Cooling (MBtu)\",\n",
    "        }\n",
    "\n",
    "        csv_file_path = os.path.join(data_folder_file_path, f\"run{upgrade_run}\", \"run\", \"results_annual.csv\")\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            print(\"Upgrade not applicable, returning empty row\")\n",
    "            metadata_dict[\"applicable_upgrade\"] = False\n",
    "            metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "            df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "            df_mp = pd.concat([previous_data, df_mp])\n",
    "            return df_mp\n",
    "        csv_data = pd.read_csv(csv_file_path, header=None)\n",
    "        csv_data = csv_data.set_index(0)\n",
    "        for k,v in upgrade_csv_properties.items():\n",
    "            try:\n",
    "                metadata_dict[k] = csv_data.loc[v].iloc[0] * 293.07107\n",
    "            except Exception as e:\n",
    "                print(f\"couldn't find {k} by indexing {v} from csv_data\")\n",
    "        metadata_dict[f\"mp{input_mp}_heating_consumption\"] = metadata_dict[\"upgrade_natgas_heating_consumption\"] + metadata_dict[\"upgrade_electricity_heating_consumption\"]\n",
    "        metadata_dict[f\"mp{input_mp}_cooling_consumption\"] = metadata_dict[\"upgrade_electricity_cooling_consumption\"]\n",
    "\n",
    "        # upgrade_properties = {\n",
    "        #     \"bldg_id\":\"bldg_id\",\n",
    "        #     \"upgrade_natgas_heating_consumption\":\"out.natural_gas.heating.energy_consumption.kwh\",\n",
    "        #     \"upgrade_electricity_heating_consumption\":\"out.electricity.heating.energy_consumption.kwh\",\n",
    "        #     f\"mp{input_mp}_heating_consumption\":upgrade_properties[\"upgrade_natgas_heating_consumption\"] + upgrade_properties[\"upgrade_electricity_heating_consumption\"],\n",
    "        #     \"size_heating_system_primary_k_btu_h\":\"out.params.size_heating_system_primary_k_btu_h\",\n",
    "        #     \"size_heat_pump_backup_primary_k_btu_h\":\"out.params.size_heat_pump_backup_primary_k_btu_h\",\n",
    "        #     \"size_heating_system_secondary_k_btu_h\":\"out.params.size_heating_system_secondary_k_btu_h\",\n",
    "        #     \"base_heating_fuel\":\"in.hvac_heating_type_and_fuel\",\n",
    "        #     \"baseline_heating_type\":\"in.hvac_heating_type\",\n",
    "        # }\n",
    "    \n",
    "    metadata_dict = {k:[v] for k,v in metadata_dict.items()}\n",
    "    df_mp = pd.DataFrame.from_dict(metadata_dict, orient=\"columns\")\n",
    "    \n",
    "    # Load the JSON data\n",
    "    # data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # # Placeholder dictionary to store the extracted properties\n",
    "    # df_mp = pd.DataFrame(columns=[\n",
    "    #     'bldg_id',\n",
    "    #     'in.hvac_has_ducts',\n",
    "    #     'in.hvac_heating_type_and_fuel',\n",
    "    #     'in.hvac_heating_efficiency',\n",
    "    #     'in.hvac_heating_type_and_fuel',\n",
    "    #     'out.params.size_heat_pump_backup_primary_k_btu_h',\n",
    "    #     'out.params.size_heating_system_primary_k_btu_h',\n",
    "    #     'out.params.size_heating_system_secondary_k_btu_h',\n",
    "    #     'upgrade.hvac_heating_efficiency',\n",
    "    # ])\n",
    "\n",
    "    # # Assuming 'BuildExistingModel' is the primary section of interest:\n",
    "    # if 'BuildExistingModel' in data:\n",
    "    #     model_data = data['BuildExistingModel']\n",
    "        \n",
    "    #     # Extract each required property if it exists in the JSON\n",
    "    #     for prop in required_properties:\n",
    "    #         df_mp[prop] = model_data.get(prop, None)  # Use None if property is missing\n",
    "    \n",
    "\n",
    "    df_mp = pd.concat([previous_data, df_mp])\n",
    "    # print(df_mp.shape)\n",
    "    # if baseline_data is not None:\n",
    "    #     if stack_not_merge:\n",
    "    #         df_mp = df_mp.append(baseline_data)\n",
    "    #     else:\n",
    "    #         df_mp = pd.merge(baseline_data, df_mp, how='inner', on = 'bldg_id')\n",
    "    #     # Run the enduse_compare function as well\n",
    "    #     # df_mp = df_enduse_compare(df_mp, input_mp, 0, df_resstock_run_am)\n",
    "\n",
    "    return df_mp\n",
    "\n",
    "# load_resstock_run_annual_metadata(os.path.abspath(os.getcwd()), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_multiple_resstock_run_annual_metadata(data_folder_file_path, input_mp, num_datapoints, baseline_data=None):\n",
    "    df_mp = None\n",
    "\n",
    "    for i in range(num_datapoints):\n",
    "        df_mp = load_resstock_run_annual_metadata(data_folder_file_path, input_mp, previous_data = df_mp, baseline_run=i+1, upgrade_run=i+1) # +num_datapoints\n",
    "    \n",
    "    if baseline_data is not None:\n",
    "        df_mp = pd.merge(baseline_data, df_mp, how='inner', on = 'bldg_id')\n",
    "    df_mp.reset_index(inplace=True, drop=True)\n",
    "    # print(df_mp)\n",
    "    return df_mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdd_factors(project_root):\n",
    "    # Factors for 2022 to 2050\n",
    "    filename = 'aeo_projections_2022_2050.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_hdd_projection_factors = pd.read_excel(io=file_path, sheet_name='hdd_factors_2022_2050')\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "    # Convert the factors dataframe into a lookup dictionary\n",
    "    hdd_factor_lookup = df_hdd_projection_factors.set_index(['census_division']).to_dict('index')\n",
    "\n",
    "    return hdd_factor_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cdd_factors(project_root):\n",
    "    # Factors for 2022 to 2050\n",
    "    filename = 'aeo_projections_2022_2050.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_cdd_projection_factors = pd.read_excel(io=file_path, sheet_name='cdd_factors_2022_2050')\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "    # Convert the factors dataframe into a lookup dictionary\n",
    "    cdd_factor_lookup = df_cdd_projection_factors.set_index(['census_division']).to_dict('index')\n",
    "\n",
    "    return cdd_factor_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_puma_medianIncome(project_root, cpi_ratio_2023_2022):\n",
    "    # Collect Area Median Income Data at PUMA-resolution\n",
    "    filename = \"nhgis0003_ds261_2022_puma.csv\"\n",
    "    relative_path = os.path.join(r\"equity_data\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_puma_medianIncome = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    # df_puma_medianIncome = df_puma_medianIncome.drop(0)\n",
    "    df_puma_medianIncome = df_puma_medianIncome.reset_index(drop=True)\n",
    "\n",
    "    cols_interest = ['GISJOIN', 'STUSAB', 'PUMAA', 'NAME_E', 'AP2PE001', 'AP2PM001']\n",
    "    df_puma_medianIncome = df_puma_medianIncome[cols_interest]\n",
    "    df_puma_medianIncome = df_puma_medianIncome.rename(columns={\"GISJOIN\": \"gis_joinID_puma\", \"STUSAB\": \"state_abbrev\", \"PUMAA\": \"puma_code\", \"NAME_E\": \"name_estimate\", \"AP2PE001\": \"median_income_USD2022\", \"AP2PM001\": \"median_income_USD2022_marginOfError\"})\n",
    "    df_puma_medianIncome['median_income_USD2023'] = round((df_puma_medianIncome['median_income_USD2022'] * cpi_ratio_2023_2022), 2)\n",
    "    return df_puma_medianIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_county_medianIncome(project_root, cpi_ratio_2023_2022):\n",
    "    # Collect Area Median Income Data at county-resolution\n",
    "    filename = \"nhgis0005_ds261_2022_county.csv\"\n",
    "    relative_path = os.path.join(r\"equity_data\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_county_medianIncome = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    # df_county_medianIncome = df_county_medianIncome.drop(0)\n",
    "    df_county_medianIncome = df_county_medianIncome.reset_index(drop=True)\n",
    "\n",
    "    cols_interest = ['GISJOIN', 'STUSAB', 'COUNTYA', 'NAME_E', 'AP2PE001', 'AP2PM001']\n",
    "    df_county_medianIncome = df_county_medianIncome[cols_interest]\n",
    "    df_county_medianIncome = df_county_medianIncome.rename(columns={\"GISJOIN\": \"gis_joinID_county\", \"STUSAB\": \"state_abbrev\", \"COUNTYA\": \"county_code\", \"NAME_E\": \"name_estimate\", \"AP2PE001\": \"median_income_USD2022\", \"AP2PM001\": \"median_income_USD2022_marginOfError\"})\n",
    "    df_county_medianIncome['median_income_USD2023'] = round((df_county_medianIncome['median_income_USD2022'] * cpi_ratio_2023_2022), 2)\n",
    "    return df_county_medianIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_state_medianIncome(project_root, cpi_ratio_2023_2022):\n",
    "    # Collect Area Median Income Data at state-resolution\n",
    "    filename = \"nhgis0004_ds261_2022_state.csv\"\n",
    "    relative_path = os.path.join(r\"equity_data\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_state_medianIncome = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "    # df_state_medianIncome = df_state_medianIncome.drop(0)\n",
    "    df_state_medianIncome = df_state_medianIncome.reset_index(drop=True)\n",
    "\n",
    "    cols_interest = ['GISJOIN', 'STUSAB','STATEA', 'NAME_E', 'AP2PE001', 'AP2PM001']\n",
    "    df_state_medianIncome = df_state_medianIncome[cols_interest]\n",
    "    df_state_medianIncome = df_state_medianIncome.rename(columns={\"GISJOIN\": \"gis_joinID_state\", \"STUSAB\": \"state_abbrev\", \"STATEA\": \"state_code\", \"NAME_E\": \"name_estimate\", \"AP2PE001\": \"median_income_USD2022\", \"AP2PM001\": \"median_income_USD2022_marginOfError\"})\n",
    "    df_state_medianIncome['median_income_USD2023'] = round((df_state_medianIncome['median_income_USD2022'] * cpi_ratio_2023_2022), 2)\n",
    "    return df_state_medianIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rsMeans_CCI_values(project_root, df_resstock_run):\n",
    "    # Adjust for regional cost differences with RSMeans\n",
    "    filename = \"rsMeans_cityCostIndex.csv\"\n",
    "    relative_path = os.path.join(r\"inflation_data\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_rsMeans_cityCostIndex = pd.read_csv(file_path)\n",
    "\n",
    "    df_rsMeans_cityCostIndex = pd.DataFrame({\n",
    "        'State': df_rsMeans_cityCostIndex['State'],\n",
    "        'City': df_rsMeans_cityCostIndex['City'],\n",
    "        'Material': (df_rsMeans_cityCostIndex['Material']).round(2),\n",
    "        'Installation': (df_rsMeans_cityCostIndex['Installation']).round(2),\n",
    "        'Average': (df_rsMeans_cityCostIndex['Average']).round(2),\n",
    "    })\n",
    "    average_cost_map = df_rsMeans_cityCostIndex.set_index('City')['Average'].to_dict()\n",
    "\n",
    "    def map_average_cost(city):\n",
    "        if city in average_cost_map:\n",
    "            return average_cost_map[city]\n",
    "        elif city == 'Not in a census Place' or city == 'In another census Place':\n",
    "            return average_cost_map.get('+30 City Average')\n",
    "        else:\n",
    "            return average_cost_map.get('+30 City Average')\n",
    "\n",
    "    # Use CCI to adjust for cost differences when compared to the national average\n",
    "    # Call the function and map the values for CCI adjustment\n",
    "    df_resstock_run['rsMeans_CCI_avg'] = df_resstock_run['city'].apply(map_average_cost)\n",
    "    return df_resstock_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rsMeans_national_avg(cpi_ratio_2023_2019):\n",
    "    return round((3.00 * (cpi_ratio_2023_2019)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create a fuel price lookup dictionary without policy_scenario from row\n",
    "def create_fuel_price_lookup(df, policy_scenario):\n",
    "    lookup_dict = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        location = row['location_map']\n",
    "        fuel_type = row['fuel_type']\n",
    "        \n",
    "        if location not in lookup_dict:\n",
    "            lookup_dict[location] = {}\n",
    "        \n",
    "        if fuel_type not in lookup_dict[location]:\n",
    "            lookup_dict[location][fuel_type] = {}\n",
    "        \n",
    "        if policy_scenario not in lookup_dict[location][fuel_type]:\n",
    "            lookup_dict[location][fuel_type][policy_scenario] = {}\n",
    "        \n",
    "        for year in range(2022, 2051):\n",
    "            column_name = f\"{year}_fuelPrice_perkWh\"\n",
    "            lookup_dict[location][fuel_type][policy_scenario][year] = row[column_name]\n",
    "    \n",
    "    return lookup_dict\n",
    "\n",
    "# Define function to project future prices with fallback to 'National'\n",
    "def project_future_prices(row, factor_dict, policy_scenario):\n",
    "    loc = row['census_division']\n",
    "    fuel = row['fuel_type']\n",
    "    price_2022 = row['2022_fuelPrice_perkWh']\n",
    "\n",
    "    # print(f\"\\nProcessing location: {loc}, fuel: {fuel}, policy_scenario: {policy_scenario}\")\n",
    "    # print(f\"Initial price for 2022: {price_2022}\")\n",
    "\n",
    "    # First, try to fetch the projection factors for the specific region\n",
    "    projection_factors = factor_dict.get((loc, fuel, policy_scenario))\n",
    "    \n",
    "    # If no factors are found for the specific region, default to 'National'\n",
    "    if not projection_factors:\n",
    "        # print(f\"No projection factors found for {loc}, {fuel}, {policy_scenario}. Defaulting to 'National'.\")\n",
    "        projection_factors = factor_dict.get(('National', fuel, policy_scenario))\n",
    "        \n",
    "    if projection_factors:\n",
    "        pass\n",
    "        # print(f\"Using projection factors for {loc if projection_factors else 'National'}, {fuel}, {policy_scenario}: {projection_factors}\")\n",
    "    else:\n",
    "        # print(f\"No projection factors found for 'National', {fuel}, {policy_scenario} either. Cannot project future prices.\")\n",
    "        return pd.Series()  # Return an empty Series if no factors are found\n",
    "\n",
    "    future_prices = {}\n",
    "    for year in range(2022, 2051):\n",
    "        if projection_factors and year in projection_factors:\n",
    "            factor = projection_factors[year]\n",
    "            future_price = price_2022 * factor\n",
    "            future_prices[f'{year}_fuelPrice_perkWh'] = future_price\n",
    "            # print(f\"Year: {year}, Factor: {factor}, Future Price: {future_price}\")\n",
    "        else:\n",
    "            print(f\"Missing factor for year {year} in {loc if projection_factors else 'National'}, {fuel}, {policy_scenario}. Skipping this year.\")\n",
    "    \n",
    "    return pd.Series(future_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fuel_price_lookups(project_root, cpi_ratio_2023_2018, cpi_ratio_2023_2019, cpi_ratio_2023_2020, cpi_ratio_2023_2021, cpi_ratio_2023_2022):\n",
    "    filename = 'fuel_prices_nominal.csv'\n",
    "    relative_path = os.path.join(r\"fuel_prices\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_fuelPrices_perkWh = pd.read_csv(file_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "    # New units for the converted and inflated prices below\n",
    "    # $USD-2023, PREVIOUSLY USED $USD-2021\n",
    "    df_fuelPrices_perkWh['units'] = 'USD2022 per kWh'\n",
    "\n",
    "    years = ['2018', '2019', '2020', '2021', '2022']\n",
    "\n",
    "    # Take dataframe with nominal prices in their base units and convert to $/kWh equivalent\n",
    "    # https://www.eia.gov/energyexplained/units-and-calculators/british-thermal-units.php\n",
    "    for year in years:\n",
    "        for index, row in df_fuelPrices_perkWh.iterrows():\n",
    "            \n",
    "            # Propane: (dollars per gallon) * (1 gallon propane/91,452 BTU) * (3412 BTU/1 kWh)\n",
    "            if row['fuel_type'] == 'propane':\n",
    "                df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/91452) * (3412/1)\n",
    "            \n",
    "            # Fuel Oil: (dollars/gallon) * (1 gallon heating oil/138,500 BTU) * (3412 BTU/1 kWh)\n",
    "            elif row['fuel_type'] == 'fuelOil':\n",
    "                df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/138500) * (3412/1)\n",
    "            \n",
    "            # Natural Gas: (dollars/cf) * (thousand cf/1000 cf) * (1 cf natural gas/1039 BTU) * (3412 BTU/1 kWh)\n",
    "            elif row['fuel_type'] == 'naturalGas':\n",
    "                # print(\"SENSITIVITY ANALYSIS: MAKING NATURAL GAS COSTS 3% LOWER\")\n",
    "                df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] * (1/1000) * (1/1039) * (3412/1) # * 0.97\n",
    "            \n",
    "            # Electricity: convert cents per kWh to $ per kWh\n",
    "            elif row['fuel_type'] == 'electricity':\n",
    "                # print(\"SENSITIVITY ANALYSIS: MAKING ELECTRICITY COSTS 3% LOWER\")\n",
    "                df_fuelPrices_perkWh.at[index, f'{year}_fuelPrice_perkWh'] = row[f'{year}_nominal_unit_price'] / 100 # * 0.97\n",
    "\n",
    "    # Convert nominal dollars to real 2022 US dollars (USD2022)\n",
    "    # $USD-2023, PREVIOUSLY USED $USD-2021\n",
    "    df_fuelPrices_perkWh['2018_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2018_fuelPrice_perkWh'] * cpi_ratio_2023_2018\n",
    "    df_fuelPrices_perkWh['2019_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2019_fuelPrice_perkWh'] * cpi_ratio_2023_2019\n",
    "    df_fuelPrices_perkWh['2020_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2020_fuelPrice_perkWh'] * cpi_ratio_2023_2020\n",
    "    df_fuelPrices_perkWh['2021_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2021_fuelPrice_perkWh'] * cpi_ratio_2023_2021\n",
    "    df_fuelPrices_perkWh['2022_fuelPrice_perkWh'] = df_fuelPrices_perkWh['2022_fuelPrice_perkWh'] * cpi_ratio_2023_2022\n",
    "\n",
    "    # Original dictionary mapping census divisions to states\n",
    "    map_states_census_divisions = {\n",
    "        \"New England\": [\"CT\", \"ME\", \"MA\", \"NH\", \"RI\", \"VT\"],\n",
    "        \"Middle Atlantic\": [\"NJ\", \"NY\", \"PA\"],\n",
    "        \"East North Central\": [\"IN\", \"IL\", \"MI\", \"OH\", \"WI\"],\n",
    "        \"West North Central\": [\"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"],\n",
    "        \"South Atlantic\": [\"DE\", \"DC\", \"FL\", \"GA\", \"MD\", \"NC\", \"SC\", \"VA\", \"WV\"],\n",
    "        \"East South Central\": [\"AL\", \"KY\", \"MS\", \"TN\"],\n",
    "        \"West South Central\": [\"AR\", \"LA\", \"OK\", \"TX\"],\n",
    "        \"Mountain\": [\"AZ\", \"CO\", \"ID\", \"NM\", \"MT\", \"UT\", \"NV\", \"WY\"],\n",
    "        \"Pacific\": [\"AK\", \"CA\", \"HI\", \"OR\", \"WA\"]\n",
    "    }\n",
    "\n",
    "    # Reverse the mapping to create a state-to-census-division map\n",
    "    state_to_census_division = {}\n",
    "    for division, states in map_states_census_divisions.items():\n",
    "        for state in states:\n",
    "            state_to_census_division[state] = division\n",
    "\n",
    "    # Function to map location to census division\n",
    "    def map_location_to_census_division(location):\n",
    "        if location in state_to_census_division:\n",
    "            return state_to_census_division[location]\n",
    "        return location\n",
    "\n",
    "    # Apply the function to map locations using .loc\n",
    "    df_fuelPrices_perkWh.loc[:, 'census_division'] = df_fuelPrices_perkWh['location_map'].apply(map_location_to_census_division)\n",
    "\n",
    "    # Project Fuel Prices from 2022 to 2050\n",
    "    filename = 'aeo_projections_2022_2050.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_fuelPrices_projection_factors = pd.read_excel(io=file_path, sheet_name='fuel_price_factors_2022_2050')\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(df_fuelPrices_projection_factors)\n",
    "\n",
    "    # Convert the factors dataframe into a lookup dictionary including policy_scenario\n",
    "    factor_dict = df_fuelPrices_projection_factors.set_index(['region', 'fuel_type', 'policy_scenario']).to_dict('index')\n",
    "\n",
    "    # Pre-IRA policy_scenario: No Inflation Reduction Act\n",
    "    # Pass the desired policy_scenario as a parameter when applying the function\n",
    "    preIRA_projected_prices_df = df_fuelPrices_perkWh.apply(lambda row: project_future_prices(row, factor_dict, 'No Inflation Reduction Act'), axis=1)\n",
    "\n",
    "    # Concatenate the projected prices with the original DataFrame\n",
    "    df_fuelPrices_perkWh_preIRA = pd.concat([df_fuelPrices_perkWh, preIRA_projected_prices_df], axis=1)\n",
    "\n",
    "    # Create Fuel Price Lookup with the policy_scenario included\n",
    "    preIRA_fuel_price_lookup = create_fuel_price_lookup(df_fuelPrices_perkWh_preIRA, 'No Inflation Reduction Act')\n",
    "\n",
    "    # IRA-Reference policy_scenario: AEO2023 Reference Case\n",
    "    # Pass the desired policy_scenario as a parameter when applying the function\n",
    "    iraRef_projected_prices_df = df_fuelPrices_perkWh.apply(lambda row: project_future_prices(row, factor_dict, 'AEO2023 Reference Case'), axis=1)\n",
    "\n",
    "    # Concatenate the projected prices with the original DataFrame\n",
    "    df_fuelPrices_perkWh_iraRef = pd.concat([df_fuelPrices_perkWh, iraRef_projected_prices_df], axis=1)\n",
    "\n",
    "    # Create Fuel Price Lookup with the policy_scenario included\n",
    "    iraRef_fuel_price_lookup = create_fuel_price_lookup(df_fuelPrices_perkWh_iraRef, 'AEO2023 Reference Case')\n",
    "\n",
    "    return preIRA_fuel_price_lookup, iraRef_fuel_price_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cambium_lookup(project_root):\n",
    "    # CAMBIUM 2021 FOR PRE-IRA SCENARIO\n",
    "    filename = 'cambium21_midCase_ba.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_cambium21_margEmis_electricity = pd.read_excel(io=file_path, sheet_name='cambium21_midCase_ba')\n",
    "\n",
    "    # print(f\"\"\"\n",
    "    # Retrieved data for filename: {filename}\n",
    "    # Located at filepath: {file_path}\n",
    "\n",
    "    # Loading dataframe ...\n",
    "    # Creating lookup dictionary for LRMER ...\n",
    "    # -------------------------------------------------------------------------------------------------------\n",
    "    # \"\"\")\n",
    "\n",
    "    # Create a new DataFrame to store interpolated results\n",
    "    interpolated_data = []\n",
    "\n",
    "    # Group by 'scenario' and 'reeds_balancing_area'\n",
    "    grouped = df_cambium21_margEmis_electricity.groupby(['scenario', 'state', 'reeds_balancing_area'])\n",
    "\n",
    "    for (scenario, state, reeds_balancing_area), group in grouped:\n",
    "        years = group['year'].values\n",
    "        values = group['lrmer_co2e_kg_per_MWh'].values\n",
    "\n",
    "        # Define a function for interpolation over the known points\n",
    "        f = interp1d(years, values, kind='linear')\n",
    "\n",
    "        # Generate years in 1-year increments between the minimum and maximum\n",
    "        new_years = np.arange(years.min(), years.max() + 1)\n",
    "\n",
    "        # Interpolate the values for these new years\n",
    "        new_values = f(new_years)\n",
    "\n",
    "        # Store the results\n",
    "        interpolated_group = pd.DataFrame({\n",
    "            'scenario': scenario,\n",
    "            'state': state,\n",
    "            'reeds_balancing_area': reeds_balancing_area,\n",
    "            'year': new_years,\n",
    "            'lrmer_co2e_kg_per_MWh': new_values\n",
    "        })\n",
    "\n",
    "        interpolated_data.append(interpolated_group)\n",
    "\n",
    "    # Concatenate all the interpolated data into a single DataFrame\n",
    "    df_cambium21_margEmis_electricity = pd.concat(interpolated_data).reset_index(drop=True)\n",
    "\n",
    "    # Convert to $USD2023 per lb\n",
    "    df_cambium21_margEmis_electricity['lrmer_co2e_ton_per_MWh'] = df_cambium21_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000)\n",
    "    df_cambium21_margEmis_electricity['lrmer_co2e_ton_per_kWh'] = df_cambium21_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000) * (1/1000)\n",
    "\n",
    "    # Create the nested lookup dictionary for mt CO2e per MWh\n",
    "    emis_preIRA_cambium21_lookup = {}\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for _, row in df_cambium21_margEmis_electricity.iterrows():\n",
    "        outer_key = (row['scenario'], row['state'], row['reeds_balancing_area'])\n",
    "        year = row['year']\n",
    "        co2e_value = row['lrmer_co2e_ton_per_kWh']\n",
    "        \n",
    "        # Initialize the outer key if not already present\n",
    "        if outer_key not in emis_preIRA_cambium21_lookup:\n",
    "            emis_preIRA_cambium21_lookup[outer_key] = {}\n",
    "        \n",
    "        # Assign the year and co2e value in the inner dictionary\n",
    "        emis_preIRA_cambium21_lookup[outer_key][year] = co2e_value\n",
    "    \n",
    "    # CAMBIUM 2021 FOR PRE-IRA SCENARIO\n",
    "    filename = 'cambium22_allScenarios_ba.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_cambium22_2024_margEmis_electricity = pd.read_excel(io=file_path, sheet_name='cambium22_scenarios_2024_ba')\n",
    "\n",
    "    # print(f\"\"\"\n",
    "    # Retrieved data for filename: {filename}\n",
    "    # Located at filepath: {file_path}\n",
    "\n",
    "    # Loading dataframe ...\n",
    "    # Creating lookup dictionary for 2024 LRMER ...\n",
    "    # -------------------------------------------------------------------------------------------------------\n",
    "    # \"\"\")\n",
    "\n",
    "    # Convert to $USD2023 per lb\n",
    "    df_cambium22_2024_margEmis_electricity['lrmer_co2e_ton_per_MWh'] = df_cambium22_2024_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000)\n",
    "    df_cambium22_2024_margEmis_electricity['lrmer_co2e_ton_per_kWh'] = df_cambium22_2024_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000) * (1/1000)\n",
    "\n",
    "    emis_IRA_2024_cambium22_lookup = {}\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for _, row in df_cambium22_2024_margEmis_electricity.iterrows():\n",
    "        outer_key = (row['scenario'], row['state'], row['reeds_balancing_area'])\n",
    "        year = row['year']\n",
    "        co2e_value = row['lrmer_co2e_ton_per_kWh']\n",
    "        \n",
    "        # Initialize the outer key if not already present\n",
    "        if outer_key not in emis_IRA_2024_cambium22_lookup:\n",
    "            emis_IRA_2024_cambium22_lookup[outer_key] = {}\n",
    "        \n",
    "        # Assign the year and co2e value in the inner dictionary\n",
    "        emis_IRA_2024_cambium22_lookup[outer_key][year] = co2e_value\n",
    "    \n",
    "    # CAMBIUM 2023 FOR IRA REFERENCE SCENARIO\n",
    "    filename = 'cambium23_allScenarios_ba.xlsx'\n",
    "    relative_path = os.path.join(r\"projections\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "    df_cambium23_margEmis_electricity = pd.read_excel(io=file_path, sheet_name='cambium23_allScenarios_ba')\n",
    "\n",
    "    # print(f\"\"\"\n",
    "    # Retrieved data for filename: {filename}\n",
    "    # Located at filepath: {file_path}\n",
    "\n",
    "    # Loading dataframe ...\n",
    "    # Creating lookup dictionary for 2025-2050 LRMER ...\n",
    "    # -------------------------------------------------------------------------------------------------------\n",
    "    # \"\"\")\n",
    "    # Create a new DataFrame to store interpolated results\n",
    "    interpolated_data = []\n",
    "\n",
    "    # Group by 'scenario' and 'reeds_balancing_area'\n",
    "    grouped = df_cambium23_margEmis_electricity.groupby(['scenario', 'state', 'reeds_balancing_area'])\n",
    "\n",
    "    for (scenario, state, reeds_balancing_area), group in grouped:\n",
    "        years = group['year'].values\n",
    "        values = group['lrmer_co2e_kg_per_MWh'].values\n",
    "\n",
    "        # Define a function for interpolation over the known points\n",
    "        f = interp1d(years, values, kind='linear')\n",
    "\n",
    "        # Generate years in 1-year increments between the minimum and maximum\n",
    "        new_years = np.arange(years.min(), years.max() + 1)\n",
    "\n",
    "        # Interpolate the values for these new years\n",
    "        new_values = f(new_years)\n",
    "\n",
    "        # Store the results\n",
    "        interpolated_group = pd.DataFrame({\n",
    "            'scenario': scenario,\n",
    "            'state': state,\n",
    "            'reeds_balancing_area': reeds_balancing_area,\n",
    "            'year': new_years,\n",
    "            'lrmer_co2e_kg_per_MWh': new_values\n",
    "        })\n",
    "\n",
    "        interpolated_data.append(interpolated_group)\n",
    "\n",
    "    # Concatenate all the interpolated data into a single DataFrame\n",
    "    df_cambium23_margEmis_electricity = pd.concat(interpolated_data).reset_index(drop=True)\n",
    "\n",
    "    # Convert to $USD2023 per lb\n",
    "    df_cambium23_margEmis_electricity['lrmer_co2e_ton_per_MWh'] = df_cambium23_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000)\n",
    "    df_cambium23_margEmis_electricity['lrmer_co2e_ton_per_kWh'] = df_cambium23_margEmis_electricity['lrmer_co2e_kg_per_MWh'] * (1/1000) * (1/1000)\n",
    "\n",
    "    # Create the nested lookup dictionary for mt CO2e per MWh\n",
    "    emis_IRA_2025_2050_cambium23_lookup = {}\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for _, row in df_cambium23_margEmis_electricity.iterrows():\n",
    "        outer_key = (row['scenario'], row['state'], row['reeds_balancing_area'])\n",
    "        year = row['year']\n",
    "        co2e_value = row['lrmer_co2e_ton_per_kWh']\n",
    "        \n",
    "        # Initialize the outer key if not already present\n",
    "        if outer_key not in emis_IRA_2025_2050_cambium23_lookup:\n",
    "            emis_IRA_2025_2050_cambium23_lookup[outer_key] = {}\n",
    "        \n",
    "        # Assign the year and co2e value in the inner dictionary\n",
    "        emis_IRA_2025_2050_cambium23_lookup[outer_key][year] = co2e_value\n",
    "    \n",
    "    return emis_preIRA_cambium21_lookup, emis_IRA_2024_cambium22_lookup, emis_IRA_2025_2050_cambium23_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emis_factors():\n",
    "    emis_factor_co2e_naturalGas_ton_perkWh = 228.5 * (1/1000) * (1/1000)\n",
    "    emis_factor_co2e_propane_ton_perkWh = 275.8 * (1/1000) * (1/1000)\n",
    "    emis_factor_co2e_fuelOil_ton_perkWh = 303.9 * (1/1000) * (1/1000)\n",
    "\n",
    "    return emis_factor_co2e_naturalGas_ton_perkWh, emis_factor_co2e_propane_ton_perkWh, emis_factor_co2e_fuelOil_ton_perkWh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scc(cpi_ratio_2023_2020):\n",
    "    epa_scc_usd2023_per_ton = 190 * cpi_ratio_2023_2020\n",
    "    return epa_scc_usd2023_per_ton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cpi_data(project_root):\n",
    "    # Load the BLS Inflation Data\n",
    "    filename = 'bls_cpiu_2005-2023.xlsx'\n",
    "    relative_path = os.path.join(r\"inflation_data\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "\n",
    "    # Create a pandas dataframe\n",
    "    df_bls_cpiu = pd.read_excel(file_path, sheet_name='bls_cpiu')\n",
    "\n",
    "    df_bls_cpiu = pd.DataFrame({\n",
    "        'year': df_bls_cpiu['Year'],\n",
    "        'cpiu_annual': df_bls_cpiu['Annual']\n",
    "    })\n",
    "\n",
    "    # Obtain the Annual CPIU values for the years of interest\n",
    "    bls_cpi_annual_2008 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2008)].item()\n",
    "    bls_cpi_annual_2010 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2010)].item()\n",
    "    bls_cpi_annual_2013 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2013)].item()\n",
    "    bls_cpi_annual_2018 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2018)].item()\n",
    "    bls_cpi_annual_2019 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2019)].item()\n",
    "    bls_cpi_annual_2020 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2020)].item()\n",
    "    bls_cpi_annual_2021 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2021)].item()\n",
    "    bls_cpi_annual_2022 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2022)].item()\n",
    "    bls_cpi_annual_2023 = df_bls_cpiu['cpiu_annual'].loc[(df_bls_cpiu['year'] == 2023)].item()\n",
    "\n",
    "    # Precompute constant values\n",
    "    cpi_ratio_2023_2023 = bls_cpi_annual_2023 / bls_cpi_annual_2023\n",
    "    cpi_ratio_2023_2022 = bls_cpi_annual_2023 / bls_cpi_annual_2022\n",
    "    cpi_ratio_2023_2021 = bls_cpi_annual_2023 / bls_cpi_annual_2021  # For EPA VSL (11.3M USD-2021)\n",
    "    cpi_ratio_2023_2020 = bls_cpi_annual_2023 / bls_cpi_annual_2020  # For SCC\n",
    "    cpi_ratio_2023_2019 = bls_cpi_annual_2023 / bls_cpi_annual_2019 \n",
    "    cpi_ratio_2023_2018 = bls_cpi_annual_2023 / bls_cpi_annual_2018 \n",
    "    cpi_ratio_2023_2013 = bls_cpi_annual_2023 / bls_cpi_annual_2013\n",
    "    cpi_ratio_2023_2010 = bls_cpi_annual_2023 / bls_cpi_annual_2010\n",
    "    cpi_ratio_2023_2008 = bls_cpi_annual_2023 / bls_cpi_annual_2008  # For EPA VSL and SCC\n",
    "\n",
    "    return cpi_ratio_2023_2023, cpi_ratio_2023_2022, cpi_ratio_2023_2021, cpi_ratio_2023_2020, cpi_ratio_2023_2019, cpi_ratio_2023_2018, cpi_ratio_2023_2013, cpi_ratio_2023_2010, cpi_ratio_2023_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_heating_equipment_cost(project_root):\n",
    "    # Collect Capital Cost Data for different End-uses\n",
    "    filename = \"tare_retrofit_costs_cpi.xlsx\"\n",
    "    relative_path = os.path.join(r\"retrofit_costs\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_heating_retrofit_costs = pd.read_excel(io=file_path, sheet_name='heating_costs')\n",
    "    dict_heating_equipment_cost = df_heating_retrofit_costs.set_index(['technology', 'efficiency']).to_dict(orient='index')\n",
    "    return dict_heating_equipment_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict_cooling_equipment_cost(project_root):\n",
    "    # Collect Capital Cost Data for different End-uses\n",
    "    filename = \"tare_retrofit_costs_cpi.xlsx\"\n",
    "    relative_path = os.path.join(r\"retrofit_costs\", filename)\n",
    "    file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "    # print(f\"Retrieved data for filename: {filename}\")\n",
    "    # print(f\"Located at filepath: {file_path}\")\n",
    "    # print(\"\\n\")\n",
    "\n",
    "    df_cooling_retrofit_costs = pd.read_excel(io=file_path, sheet_name='cooling_costs')\n",
    "    dict_cooling_equipment_cost = df_cooling_retrofit_costs.set_index(['technology', 'efficiency']).to_dict(orient='index')\n",
    "    return dict_cooling_equipment_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_TARE_results(df, output_file_path):\n",
    "    # Have this in a standard format required for my data parsing functions\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "    df.to_csv(output_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv38': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ee1b30de5c680242df62e4301a044656a1dd3f30b451ebab96ca477daaaf36a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
